MILKDROP_PRESET_VERSION=201
PSVERSION=4
PSVERSION_WARP=4
PSVERSION_COMP=3
[preset00]
fRating=4.500
fGammaAdj=2.300
fDecay=0.965
fVideoEchoZoom=1.025
fVideoEchoAlpha=0.450
nVideoEchoOrientation=3
nWaveMode=6
bAdditiveWaves=1
bWaveDots=0
bWaveThick=1
bModWaveAlphaByVolume=0
bMaximizeWaveColor=1
bTexWrap=1
bDarkenCenter=0
bRedBlueStereo=0
bBrighten=0
bDarken=1
bSolarize=0
bInvert=0
fWaveAlpha=0.200
fWaveScale=1.450
fWaveSmoothing=0.100
fWaveParam=0.200
fModWaveAlphaStart=0.650
fModWaveAlphaEnd=1.500
fWarpAnimSpeed=1.000
fWarpScale=1.331
fZoomExponent=1.00000
fShader=0.500
zoom=1.00000
rot=0.00000
cx=0.500
cy=0.500
dx=0.00000
dy=0.00000
warp=0.01000
sx=1.00000
sy=1.00000
wave_r=0.500
wave_g=0.500
wave_b=0.500
wave_x=0.000
wave_y=0.500
ob_size=0.000
ob_r=0.000
ob_g=0.000
ob_b=0.000
ob_a=0.000
ib_size=0.010
ib_r=0.250
ib_g=0.250
ib_b=0.250
ib_a=0.000
nMotionVectorsX=96.000
nMotionVectorsY=36.372
mv_dx=0.000
mv_dy=0.000
mv_l=5.000
mv_r=1.000
mv_g=1.000
mv_b=0.000
mv_a=0.000
b1n=0.000
b2n=0.000
b3n=0.000
b1x=1.000
b2x=1.000
b3x=1.000
b1ed=0.250
per_frame_init_1=// === NEURAL FLUX INITIALIZATION ===
per_frame_init_2=neural_phase = 0;
per_frame_init_3=flux_energy = 0;
per_frame_init_4=bass_inertia = 0;
per_frame_init_5=mid_resonance = 0;
per_frame_init_6=treb_harmonic = 0;
per_frame_init_7=beat_memory = 0;
per_frame_init_8=dimensional_ripple = 0;
per_frame_init_9=memory_decay = 0.95;
per_frame_1=// === AUDITORY CORTEX PROCESSING ===
per_frame_2=// Multi-band energy envelope followers
per_frame_3=energy_total = (bass + mid + treb) * 0.333;
per_frame_4=bass_inertia = bass_inertia * 0.85 + bass * 0.15;
per_frame_5=mid_resonance = mid_resonance * 0.88 + mid * 0.12;
per_frame_6=treb_harmonic = treb_harmonic * 0.90 + treb * 0.10;
per_frame_7=
per_frame_8=// Beat detection with temporal memory
per_frame_9=beat_threshold = 1.15 + beat_memory * 0.3;
per_frame_10=is_beat = above(bass, beat_threshold) * (1 - equal(beat_memory, 1));
per_frame_11=beat_memory = if(is_beat, 1, beat_memory * 0.92);
per_frame_12=
per_frame_13=// Neural accumulation creates flux energy
per_frame_14=flux_energy = flux_energy * 0.96 + (bass_inertia * 0.4 + mid_resonance * 0.35 + treb_harmonic * 0.25);
per_frame_15=q8 = min(flux_energy * 1.5, 3); // Global intensity
per_frame_16=
per_frame_17=// === TEMPORAL PHASE ENGINE ===
per_frame_18=neural_speed = 0.018 + flux_energy * 0.025 + is_beat * 0.12;
per_frame_19=neural_phase = neural_phase + neural_speed * (fps / 60);
per_frame_20=q1 = neural_phase;
per_frame_21=
per_frame_22=// Breathing waveform generator
per_frame_23=breath_rate = 0.4 + bass_inertia * 0.2;
per_frame_24=breath = 0.5 + 0.5 * sin(time * breath_rate + neural_phase * 0.5);
per_frame_25=q2 = breath;
per_frame_26=
per_frame_27=// Dimensional ripple spacetime distortion
per_frame_28=dimensional_ripple = dimensional_ripple * 0.88 + is_beat * 0.6;
per_frame_29=q3 = dimensional_ripple;
per_frame_30=
per_frame_31=// === TRANSFORMATION MATRIX ===
per_frame_32=// Zoom breathes with neural energy
per_frame_33=zoom_breath = sin(neural_phase * 0.3 + time * 0.2) * 0.008;
per_frame_34=zoom_pulse = 1 - bass_inertia * 0.015 + is_beat * 0.03;
per_frame_35=zoom = zoom_pulse + zoom_breath;
per_frame_36=
per_frame_37=// Rotational inertia from frequency interaction
per_frame_38=rot_inertia = (bass_inertia - mid_resonance) * 0.01 + sin(time * 0.15) * 0.002;
per_frame_39=rot = rot + rot_inertia + is_beat * 0.05;
per_frame_40=
per_frame_41=// Spatial drift through neural space
per_frame_42=cx = 0.5 + sin(neural_phase * 0.2 + time * 0.1) * 0.06;
per_frame_43=cx = cx + cos(bass_inertia * 3) * 0.03;
per_frame_44=cy = 0.5 + cos(neural_phase * 0.15 + time * 0.12) * 0.06;
per_frame_45=cy = cy + sin(mid_resonance * 3) * 0.03;
per_frame_46=
per_frame_47=// Directional flow vectors
per_frame_48=dx = sin(neural_phase * 0.4) * 0.001 + cos(time * 0.25) * 0.0005;
per_frame_49=dy = cos(neural_phase * 0.35) * 0.001 + sin(time * 0.3) * 0.0005;
per_frame_50=
per_frame_51=// Spacetime warping intensity
per_frame_52=warp_field = 0.01 + breath * 0.05 * flux_energy;
per_frame_53=warp_field = warp_field + dimensional_ripple * 0.08;
per_frame_54=warp = min(warp_field, 0.4);
per_frame_55=
per_frame_56=// Aspect ratio modulation
per_frame_57=sx = 1 + sin(neural_phase * 0.6 + time * 0.2) * 0.02;
per_frame_58=sy = 1 + cos(neural_phase * 0.55 + time * 0.18) * 0.02;
per_frame_59=
per_frame_60=// === CHROMA NEURAL MAPPING ===
per_frame_61=// RGB channels driven by separate frequency bands
per_frame_62=wave_r = 0.5 + 0.5 * sin(neural_phase + bass_inertia * 4);
per_frame_63=wave_g = 0.5 + 0.5 * sin(neural_phase * 1.3 + mid_resonance * 4 + 2.1);
per_frame_64=wave_b = 0.5 + 0.5 * sin(neural_phase * 1.7 + treb_harmonic * 4 + 4.2);
per_frame_65=
per_frame_66=// Wave position follows neural gravity
per_frame_67=wave_x = 0.5 + sin(neural_phase + time * 0.3) * 0.25;
per_frame_68=wave_y = 0.5 + cos(neural_phase * 0.8 + time * 0.25) * 0.25;
per_frame_69=
per_frame_70=// Adaptive decay creates temporal smearing
per_frame_71=decay = 0.92 - flux_energy * 0.02 - is_beat * 0.04;
per_frame_72=decay = max(0.88, min(0.98, decay));
per_frame_73=
per_frame_74=// Motion vectors visualize energy flow
per_frame_75=mv_a = 0.2 + flux_energy * 0.3;
per_frame_76=mv_r = 0.5 + sin(neural_phase * 0.3) * 0.5;
per_frame_77=mv_g = 0.5 + sin(neural_phase * 0.4 + 2.1) * 0.5;
per_frame_78=mv_b = 0.5 + sin(neural_phase * 0.5 + 4.2) * 0.5;
per_pixel_1=// === NEURAL FIELD DISTORTION CALCULUS ===
per_pixel_2=// Establish relative coordinates from center
per_pixel_3=rel_x = x - cx;
per_pixel_4=rel_y = y - cy;
per_pixel_5=dist = sqrt(rel_x * rel_x + rel_y * rel_y);
per_pixel_6=ang = atan2(rel_y, rel_x);
per_pixel_7=
per_pixel_8=// Primary neural interference pattern
per_pixel_9=neural_wave1 = sin(dist * 16 - neural_phase * 5 + ang * 4) * bass_inertia;
per_pixel_10=neural_wave2 = sin(dist * 12 + neural_phase * 4 - ang * 6) * mid_resonance;
per_pixel_11=neural_wave3 = sin(dist * 20 - neural_phase * 3 + ang * 8) * treb_harmonic;
per_pixel_12=
per_pixel_13=// Frequency-specific field generators
per_pixel_14=bass_field = cos(ang * 5 + dist * 8 + neural_phase * 2) * (bass_inertia * 0.5);
per_pixel_15=mid_field = sin(ang * 7 - dist * 12 + neural_phase * 3) * (mid_resonance * 0.5);
per_pixel_16=treb_field = cos(ang * 9 + dist * 16 - neural_phase * 4) * (treb_harmonic * 0.5);
per_pixel_17=
per_pixel_18=// Quantum superposition of all fields
per_pixel_19=total_field = neural_wave1 * 0.35 + neural_wave2 * 0.3 + neural_wave3 * 0.2;
per_pixel_20=total_field = total_field + bass_field * 0.4 + mid_field * 0.35 + treb_field * 0.3;
per_pixel_21=
per_pixel_22=// Dimensional pulse propagation
per_pixel_23=dimensional_pulse = sin(dist * 30 - time * 3 + flux_energy * 6);
per_pixel_24=
per_pixel_25=// Angular quantum segmentation
per_pixel_26=angular_quantum = sin(ang * 15 + time * 1.5 + dimensional_ripple * 4);
per_pixel_27=
per_pixel_28=// === SPACETIME DISPLACEMENT ===
per_pixel_29=displacement_magnitude = (total_field + dimensional_pulse * 0.5 + angular_quantum * 0.25) * 0.02;
per_pixel_30=displacement_magnitude = displacement_magnitude * (1 + breath * 0.5);
per_pixel_31=
per_pixel_32=// Apply to coordinate system
per_pixel_33=zoom = zoom + displacement_magnitude * sin(dist * 12);
per_pixel_34=rot = rot + displacement_magnitude * 0.5 * cos(ang * 4);
per_pixel_35=
per_pixel_36=// Dimensional warping creates reality folds
per_pixel_37=dim_factor = dimensional_ripple * sin(dist * 20 + ang * 6);
per_pixel_38=zoom = zoom + dim_factor * 0.04;
warp_1=`shader_body
warp_2=`{
warp_3=`    // === QUANTUM CONSCIOUSNESS WARP SHADER ===
warp_4=`    // Multi-dimensional reality warping with musical intelligence
warp_5=`    
warp_6=`    float2 uv_center = uv - 0.5;
warp_7=`    float dist = length(uv_center);
warp_8=`    float angle = atan2(uv_center.y, uv_center.x);
warp_9=`    
warp_10=`    // Sample current frame
warp_11=`    float3 current = tex2D(sampler_main, uv).xyz;
warp_12=`    ret = current;
warp_13=`    float3 original = ret;
warp_14=`    
warp_15=`    // === ORGANIC CONSCIOUSNESS SPREADING ===
warp_16=`    // Neural growth pattern
warp_17=`    float spread_amount = length(texsize.zw) * 6;
warp_18=`    ret = max(ret, tex2D(sampler_main, (uv - 0.5) * (1 - spread_amount) + 0.5).xyz * 0.95);
warp_19=`    ret = max(ret, tex2D(sampler_main, (uv - 0.5) * (1 + spread_amount) + 0.5).xyz * 0.95);
warp_20=`    
warp_21=`    // === DIMENSIONAL FEEDBACK LOOPS ===
warp_22=`    // Create depth through blur differential
warp_23=`    float3 blur_diff = ret - GetBlur1(uv);
warp_24=`    ret += blur_diff * 0.25;
warp_25=`    
warp_26=`    // === VOLUMETRIC CONSCIOUSNESS NOISE ===
warp_27=`    // 3D noise injection for texture complexity
warp_28=`    float noise_scale = 0.08;
warp_29=`    float noise_speed = 0.15;
warp_30=`    float4 consciousness_noise = tex3D(sampler_noisevol_hq,
warp_31=`        float3(uv * texsize.xy * texsize_noisevol_hq.zw * noise_scale,
warp_32=`               time * noise_speed + q1 * 0.3));
warp_33=`    
warp_34=`    // === QUANTUM COLOR SHIFTING ===
warp_35=`    // Musical intelligence drives channel manipulation
warp_36=`    float energy_threshold = q8;
warp_37=`    float consciousness_phase = q1;
warp_38=`    float dimensional_shift = q3;
warp_39=`    
warp_40=`    // Phase-based color rotation
warp_41=`    if (energy_threshold > 0.5) {
warp_42=`        float shift_factor = sin(consciousness_phase * 2 + dist * 5) * 0.5 + 0.5;
warp_43=`        if (shift_factor > 0.6) {
warp_44=`            ret.x = original.z * (1.0 - consciousness_noise.x * 0.3);
warp_45=`            ret.y = original.x * (1.0 - consciousness_noise.y * 0.3);
warp_46=`            ret.z = original.y * (1.0 - consciousness_noise.z * 0.3);
warp_47=`        }
warp_48=`    }
warp_49=`    
warp_50=`    // === CONDITIONAL NOISE INJECTION ===
warp_51=`    // Creates musical-reactive texture patterns
warp_52=`    float noise_threshold = 0.3 + energy_threshold * 0.2;
warp_53=`    if (ret.x > noise_threshold && ret.x < 0.8) {
warp_54=`        ret.y += consciousness_noise.x * 0.4 * energy_threshold;
warp_55=`    }
warp_56=`    if (ret.y > noise_threshold && ret.y < 0.8) {
warp_57=`        ret.z += consciousness_noise.y * 0.4 * energy_threshold;
warp_58=`    }
warp_59=`    if (ret.z > noise_threshold && ret.z < 0.8) {
warp_60=`        ret.x += consciousness_noise.z * 0.4 * energy_threshold;
warp_61=`    }
warp_62=`    
warp_63=`    // === DIMENSIONAL RIFT EFFECT ===
warp_64=`    // Strong dimensional shifts create reality tears
warp_65=`    if (dimensional_shift > 0.3) {
warp_66=`        float rift_pattern = sin(angle * 8 + time * 2) * sin(dist * 15 - time * 3);
warp_67=`        if (rift_pattern > 0.5) {
warp_68=`            ret = 1.0 - ret * 0.8;
warp_69=`        }
warp_70=`    }
warp_71=`    
warp_72=`    // === CONSCIOUSNESS DECAY ===
warp_73=`    // Intelligent temporal fade preserves intense moments
warp_74=`    float decay_rate = 0.018 - energy_threshold * 0.012;
warp_75=`    decay_rate = decay_rate - dimensional_shift * 0.01;
warp_76=`    ret -= max(0.005, decay_rate);
warp_77=`    
warp_78=`    // Ensure valid color range
warp_79=`    ret = saturate(ret);
warp_80=`}
comp_1=`shader_body
comp_2=`{
comp_3=`    float neural_power = q8;
comp_4=`    float phase = q1;
comp_5=`    float chaos = q2;
comp_6=`    
comp_7=`    uv = 0.5 + (uv - 0.5) * 0.98;
comp_8=`    
comp_9=`    // Multi-resolution gradient analysis
comp_10=`    float2 fine_d = texsize.zw * 4;
comp_11=`    float2 med_d = texsize.zw * 8;
comp_12=`    float2 coarse_d = texsize.zw * 16;
comp_13=`    
comp_14=`    float3 fine_dx = GetPixel(uv + float2(1,0) * fine_d) - GetPixel(uv - float2(1,0) * fine_d);
comp_15=`    float3 fine_dy = GetPixel(uv + float2(0,1) * fine_d) - GetPixel(uv - float2(0,1) * fine_d);
comp_16=`    float3 med_dx = GetBlur1(uv + float2(1,0) * med_d) - GetBlur1(uv - float2(1,0) * med_d);
comp_17=`    float3 med_dy = GetBlur1(uv + float2(0,1) * med_d) - GetBlur1(uv - float2(0,1) * med_d);
comp_18=`    float3 coarse_dx = GetBlur2(uv + float2(1,0) * coarse_d) - GetBlur2(uv - float2(1,0) * coarse_d);
comp_19=`    float3 coarse_dy = GetBlur2(uv + float2(0,1) * coarse_d) - GetBlur2(uv - float2(0,1) * coarse_d);
comp_20=`    
comp_21=`    // Gradient strength
comp_22=`    float gradient_strength = length(fine_dx) + length(med_dx) + length(coarse_dx);
comp_23=`    gradient_strength += length(fine_dy) + length(med_dy) + length(coarse_dy);
comp_24=`    
comp_25=`    // 3D noise with gradient coupling
comp_26=`    float tex_scale = 0.08 + chaos * 0.03;
comp_27=`    float time_scale = 0.25 + phase * 0.1;
comp_28=`    float4 synaptic_noise = tex3D(sampler_noisevol_hq,
comp_29=`        float3((uv + float2(lum(fine_dx), lum(fine_dy)) * 0.5) * 
comp_30=`               texsize.xy * texsize_noisevol_hq.zw * tex_scale,
comp_31=`               time * time_scale + phase * 0.3));
comp_32=`    
comp_33=`    // Gradient-driven displacement
comp_34=`    float2 field_force = float2(lum(med_dx), lum(med_dy)) * 0.08;
comp_35=`    field_force += float2(lum(coarse_dx), lum(coarse_dy)) * 0.05;
comp_36=`    uv -= field_force * (0.6 + neural_power * 0.4);
comp_37=`    
comp_38=`    // Multi-layer composite
comp_39=`    float3 layer_fine = GetPixel(uv);
comp_40=`    float3 layer_med = GetBlur1(uv);
comp_41=`    float3 layer_coarse = GetBlur2(uv);
comp_42=`    
comp_43=`    // Differential amplification
comp_44=`    ret = abs(layer_fine * 2.0 + layer_med - layer_coarse * 0.6);
comp_45=`    
comp_46=`    // Musical noise coupling
comp_47=`    ret *= lum(synaptic_noise) * (2.0 + neural_power * 1.0);
comp_48=`    
comp_49=`    // Contrast sculpting
comp_50=`    ret = pow(ret, float3(0.75, 0.70, 0.65));
comp_51=`    ret = ret * (1.0 + (0.5 - ret) * 0.2);
comp_52=`    
comp_53=`    // Neural inversion
comp_54=`    float invert_amount = 0.5 + neural_power * 0.2;
comp_55=`    ret = lerp(ret, 1.0 - ret, invert_amount);
comp_56=`    
comp_57=`    // Chroma shifting
comp_58=`    ret.r *= 1.02;
comp_59=`    ret.g *= 0.98;
comp_60=`    ret.b *= 1.05;
comp_61=`    
comp_62=`    ret = saturate(ret);
comp_63=`}
